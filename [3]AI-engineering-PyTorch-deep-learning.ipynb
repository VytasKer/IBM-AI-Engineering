{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib.colors import ListedColormap\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifer 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for plotting\n",
    "\n",
    "def plot_data(data_set, model = None, n = 1, color = False):\n",
    "    X = data_set[:][0]\n",
    "    Y = data_set[:][1]\n",
    "    plt.plot(X[Y == 0, 0].numpy(), Y[Y == 0].numpy(), 'bo', label = 'y = 0')\n",
    "    plt.plot(X[Y == 1, 0].numpy(), 0 * Y[Y == 1].numpy(), 'ro', label = 'y = 1')\n",
    "    plt.plot(X[Y == 2, 0].numpy(), 0 * Y[Y == 2].numpy(), 'go', label = 'y = 2')\n",
    "    plt.ylim((-0.1, 3))\n",
    "    plt.legend()\n",
    "    if model != None:\n",
    "        w = list(model.parameters())[0][0].detach()\n",
    "        b = list(model.parameters())[1][0].detach()\n",
    "        y_label = ['yhat=0', 'yhat=1', 'yhat=2']\n",
    "        y_color = ['b', 'r', 'g']\n",
    "        Y = []\n",
    "        for w, b, y_l, y_c in zip(model.state_dict()['0.weight'], model.state_dict()['0.bias'], y_label, y_color):\n",
    "            Y.append((w * X + b).numpy())\n",
    "            plt.plot(X.numpy(), (w * X + b).numpy(), y_c, label = y_l)\n",
    "        if color == True:\n",
    "            x = X.numpy()\n",
    "            x = x.reshape(-1)\n",
    "            top = np.ones(x.shape)\n",
    "            y0 = Y[0].reshape(-1)\n",
    "            y1 = Y[1].reshape(-1)\n",
    "            y2 = Y[2].reshape(-1)\n",
    "            plt.fill_between(x, y0, where = y1 > y1, interpolate = True, color = 'blue')\n",
    "            plt.fill_between(x, y0, where = y1 > y2, interpolate = True, color = 'blue')\n",
    "            plt.fill_between(x, y1, where = y1 > y0, interpolate = True, color = 'red')\n",
    "            plt.fill_between(x, y1, where = ((y1 > y2) * (y1 > y0)),interpolate = True, color = 'red')\n",
    "            plt.fill_between(x, y2, where = (y2 > y0) * (y0 > 0),interpolate = True, color = 'green')\n",
    "            plt.fill_between(x, y2, where = (y2 > y1), interpolate = True, color = 'green')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Softmax Classifier technically you only need nn.Linear\n",
    "model = nn.Sequential(nn.Linear(1, 3))\n",
    "model.state_dict()\n",
    "\n",
    "# Create criterion function, optimizer, and dataloader\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "trainloader = DataLoader(dataset = data_set, batch_size = 5)\n",
    "\n",
    "# Train the model\n",
    "LOSS = []\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % 50 == 0:\n",
    "            pass\n",
    "            plot_data(data_set, model)\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            LOSS.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "train_model(300)\n",
    "\n",
    "# Make the prediction\n",
    "z =  model(data_set.x)\n",
    "_, yhat = z.max(1)\n",
    "print(\"The prediction:\", yhat)\n",
    "\n",
    "# Print the accuracy\n",
    "correct = (data_set.y == yhat).sum().item()\n",
    "accuracy = correct / len(data_set)\n",
    "print(\"The accuracy: \", accuracy)\n",
    "\n",
    "Softmax_fn=nn.Softmax(dim=-1)\n",
    "\n",
    "Probability = Softmax_fn(z)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"probability of class {} is given by {}\".format(i, Probability[0,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and print the training dataset\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dataset:\\n \", train_dataset)\n",
    "\n",
    "# Define softmax classifier class\n",
    "class SoftMax(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        return z\n",
    "    \n",
    "# Print the shape of train dataset\n",
    "train_dataset[0][0].shape\n",
    "\n",
    "# Define the learning rate, optimizer, criterion and data loader\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 10\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "N_test = len(validation_dataset)\n",
    "\n",
    "def train_model(n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        correct = 0\n",
    "        # perform a prediction on the validationdata  \n",
    "        for x_test, y_test in validation_loader:\n",
    "            z = model(x_test.view(-1, 28 * 28))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / N_test\n",
    "        loss_list.append(loss.data)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "train_model(n_epochs)\n",
    "\n",
    "# Plot the loss and accuracy\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(loss_list,color=color)\n",
    "ax1.set_xlabel('epoch',color=color)\n",
    "ax1.set_ylabel('total loss',color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  \n",
    "ax2.plot( accuracy_list, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the misclassified samples\n",
    "Softmax_fn=nn.Softmax(dim=-1)\n",
    "count = 0\n",
    "for x, y in validation_dataset:\n",
    "    z = model(x.reshape(-1, 28 * 28))\n",
    "    _, yhat = torch.max(z, 1)\n",
    "    if yhat != y:\n",
    "        show_data((x, y))\n",
    "        plt.show()\n",
    "        print(\"yhat:\", yhat)\n",
    "        print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n",
    "        count += 1\n",
    "    if count >= 5:\n",
    "        break\n",
    "\n",
    "# Plot the classified samples\n",
    "Softmax_fn=nn.Softmax(dim=-1)\n",
    "count = 0\n",
    "for x, y in validation_dataset:\n",
    "    z = model(x.reshape(-1, 28 * 28))\n",
    "    _, yhat = torch.max(z, 1)\n",
    "    if yhat == y:\n",
    "        show_data((x, y))\n",
    "        plt.show()\n",
    "        print(\"yhat:\", yhat)\n",
    "        print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n",
    "        count += 1\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple One Hidden Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(model,data_set):\n",
    "    activations=model.activation(data_set.x)\n",
    "    for i,activation in enumerate(activations):\n",
    "        plt.hist(activation.numpy(),4,density=True)\n",
    "        plt.title(\"Activation layer \" + str(i+1))\n",
    "        plt.xlabel(\"Activation\")\n",
    "        plt.xlabel(\"Activation\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def PlotStuff(X,Y,model=None,leg=False):\n",
    "    \n",
    "    plt.plot(X[Y==0].numpy(),Y[Y==0].numpy(),'or',label='training points y=0 ' )\n",
    "    plt.plot(X[Y==1].numpy(),Y[Y==1].numpy(),'ob',label='training points y=1 ' )\n",
    "\n",
    "    if model!=None:\n",
    "        plt.plot(X.numpy(),model(X).detach().numpy(),label='neral network ')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.linspace(-20, 20, 100).view(-1,1)\n",
    "  \n",
    "        self.y=torch.zeros(self.x.shape[0])\n",
    "        self.y[(self.x[:,0]>-10)& (self.x[:,0]<-5)]=1\n",
    "        self.y[(self.x[:,0]>5)& (self.x[:,0]<10)]=1\n",
    "        self.y=self.y.view(-1,1)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):    \n",
    "            \n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.linear2=nn.Linear(H,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=torch.sigmoid(self.linear2(x))\n",
    "        return x\n",
    "\n",
    "def train(data_set,model,criterion, train_loader, optimizer, epochs=5,plot_number=10):\n",
    "    cost=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total=0\n",
    "        \n",
    "        for x,y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            yhat=model(x)\n",
    "            loss=criterion(yhat,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total+=loss.item()\n",
    "            \n",
    "        if epoch%plot_number==0:\n",
    "            PlotStuff(data_set.x,data_set.y,model)\n",
    "        \n",
    "        cost.append(total)\n",
    "    plt.figure()\n",
    "    plt.plot(cost)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('cost')\n",
    "    plt.show()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=Data()\n",
    "PlotStuff(data_set.x,data_set.y,leg=False)\n",
    "torch.manual_seed(0)\n",
    "model=Net(1,9,1)\n",
    "learning_rate=0.1\n",
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loader=DataLoader(dataset=data_set,batch_size=100)\n",
    "COST=train(data_set,model,criterion, train_loader, optimizer, epochs=600,plot_number=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks with One Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot accuracy and loss\n",
    "def plot_accuracy_loss(training_results): \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(training_results['training_loss'], 'r')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('training loss iterations')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(training_results['validation_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epochs')   \n",
    "    plt.show()\n",
    "\n",
    "# Define a function to plot model parameters\n",
    "def print_model_parameters(model):\n",
    "    count = 0\n",
    "    for ele in model.state_dict():\n",
    "        count += 1\n",
    "        if count % 2 != 0:\n",
    "            print (\"The following are the parameters for the layer \", count // 2 + 1)\n",
    "        if ele.find(\"bias\") != -1:\n",
    "            print(\"The size of bias: \", model.state_dict()[ele].size())\n",
    "        else:\n",
    "            print(\"The size of weights: \", model.state_dict()[ele].size())\n",
    "\n",
    "# Define a function to display data\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample.numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Neural Network class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    # Prediction    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))  \n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28 * 28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = Net(input_dim, hidden_dim, output_dim)\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs = 10)\n",
    "plot_accuracy_loss(training_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions. Test Sigmoid, Tanh, and Relu Activations Functions on the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with sigmoid function\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))  \n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with Tanh function\n",
    "class NetTanh(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(NetTanh, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with Relu function\n",
    "class NetRelu(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(NetRelu, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for training the model\n",
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss':[], 'validation_accuracy':[]}  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.item())\n",
    "\n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            _, label=torch.max(z, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "\n",
    "    return useful_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model with sigmoid function\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)\n",
    "\n",
    "# Train a model with Tanh function\n",
    "model_Tanh = NetTanh(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.SGD(model_Tanh.parameters(), lr=learning_rate)\n",
    "training_results_tanch = train(model_Tanh, criterion, train_loader, validation_loader, optimizer, epochs=30)\n",
    "\n",
    "# Train a model with Relu function\n",
    "modelRelu = NetRelu(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\n",
    "training_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the training loss\n",
    "plt.plot(training_results_tanch['training_loss'], label='tanh')\n",
    "plt.plot(training_results['training_loss'], label='sigmoid')\n",
    "plt.plot(training_results_relu['training_loss'], label='relu')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training loss iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model class using sigmoid as the activation function\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self,x):\n",
    "        x = torch.sigmoid(self.linear1(x)) \n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This Net class is the best because you can use it to make custom models automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Net model class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size, output_size))\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, activation):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                activation = F.relu(linear_transform(activation))\n",
    "            else:\n",
    "                activation = linear_transform(activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for training the model\n",
    "def train(data_set, model, criterion, train_loader, optimizer, epochs=100):\n",
    "    LOSS = []\n",
    "    ACC = []\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            LOSS.append(loss.item())\n",
    "        ACC.append(accuracy(model, data_set))\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(LOSS, color = color)\n",
    "    ax1.set_xlabel('Iteration', color = color)\n",
    "    ax1.set_ylabel('total loss', color = color)\n",
    "    ax1.tick_params(axis = 'y', color = color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color = color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(ACC, color = color)\n",
    "    ax2.tick_params(axis = 'y', color = color)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "    plt.show()\n",
    "    return LOSS\n",
    "\n",
    "# The function to calculate the accuracy\n",
    "def accuracy(model, data_set):\n",
    "    _, yhat = torch.max(model(data_set.x), 1)\n",
    "    return (yhat == data_set.y).numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with 1 hidden layer with 50 neurons\n",
    "Layers = [2, 50, 3]\n",
    "model = Net(Layers)\n",
    "learning_rate = 0.10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_loader = DataLoader(dataset=data_set, batch_size=20)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n",
    "\n",
    "plot_decision_regions_3class(model, data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Dropout for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Net Class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, in_size, n_hidden, out_size, p=0):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.linear1 = nn.Linear(in_size, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear3 = nn.Linear(n_hidden, out_size)\n",
    "    \n",
    "    # Prediction function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.drop(self.linear1(x)))\n",
    "        x = F.relu(self.drop(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Uniform, Default and Xavier Uniform Initialization on MNIST dataset with tanh activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network with Xavier initialization\n",
    "class Net_Xavier(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net_Xavier, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            torch.nn.init.xavier_uniform_(linear.weight)\n",
    "            self.hidden.append(linear)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                x = torch.tanh(linear_transform(x))\n",
    "            else:\n",
    "                x = linear_transform(x)\n",
    "        return x\n",
    "\n",
    "# Define the neural network with Uniform initialization\n",
    "class Net_Uniform(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net_Uniform, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            linear.weight.data.uniform_(0, 1)\n",
    "            self.hidden.append(linear)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                x = torch.tanh(linear_transform(x))\n",
    "            else:\n",
    "                x = linear_transform(x)\n",
    "        return x\n",
    "    \n",
    "# Define the neural network with Default initialization\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            self.hidden.append(linear)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                x = torch.tanh(linear_transform(x))\n",
    "            else:\n",
    "                x = linear_transform(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum with Different Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the fourth order polynomial \n",
    "def fourth_order(yhat): \n",
    "    out = torch.mean(2 * (yhat ** 4) - 9 * (yhat ** 3) - 21 * (yhat ** 2) + 88 * yhat + 48)\n",
    "    return out\n",
    "\n",
    "# Make the prediction with momentum\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.001, momentum=0.9)\n",
    "plot_fourth_order(w, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization with the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network Model using Batch Normalization\n",
    "class NetBatchNorm(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, in_size, n_hidden1, n_hidden2, out_size):\n",
    "        super(NetBatchNorm, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_size, n_hidden1)\n",
    "        self.linear2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.linear3 = nn.Linear(n_hidden2, out_size)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden2)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(torch.sigmoid(self.linear1(x)))\n",
    "        x = self.bn2(torch.sigmoid(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "    # Activations, to analyze results \n",
    "    def activation(self, x):\n",
    "        out = []\n",
    "        z1 = self.bn1(self.linear1(x))\n",
    "        out.append(z1.detach().numpy().reshape(-1))\n",
    "        a1 = torch.sigmoid(z1)\n",
    "        out.append(a1.detach().numpy().reshape(-1).reshape(-1))\n",
    "        z2 = self.bn2(self.linear2(a1))\n",
    "        out.append(z2.detach().numpy().reshape(-1))\n",
    "        a2 = torch.sigmoid(z2)\n",
    "        out.append(a2.detach().numpy().reshape(-1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# load the train dataset\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Create Data Loader for both train and validating\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=3)\n",
    "conv\n",
    "\n",
    "conv.state_dict()['weight'][0][0]=torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0.0,-1.0]])\n",
    "conv.state_dict()['bias'][0]=0.0\n",
    "conv.state_dict()\n",
    "\n",
    "image=torch.zeros(1,1,5,5)\n",
    "image[0,0,:,2]=1\n",
    "image\n",
    "\n",
    "z=conv(image)\n",
    "z\n",
    "\n",
    "# With padding (adding zeros to the image)\n",
    "conv5 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=3,padding=1)\n",
    "\n",
    "conv5.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
    "conv5.state_dict()['bias'][0]=0.0\n",
    "conv5.state_dict()\n",
    "z5=conv5(image1)\n",
    "print(\"z5:\",z5)\n",
    "print(\"z5:\",z4.shape[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function and Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=torch.zeros(1,1,4,4)\n",
    "image1[0,0,0,:]=torch.tensor([1.0,2.0,3.0,-4.0])\n",
    "image1[0,0,1,:]=torch.tensor([0.0,2.0,-3.0,0.0])\n",
    "image1[0,0,2,:]=torch.tensor([0.0,2.0,3.0,1.0])\n",
    "\n",
    "image1\n",
    "\n",
    "max1=torch.nn.MaxPool2d(2,stride=1)\n",
    "max1(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Input and Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More outputs\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=3,kernel_size=3)\n",
    "\n",
    "# More inputs\n",
    "conv3 = nn.Conv2d(in_channels=2, out_channels=1,kernel_size=3)\n",
    "\n",
    "# Multiple outputs and inputs\n",
    "conv4 = nn.Conv2d(in_channels=2, out_channels=3,kernel_size=3)\n",
    "conv4.state_dict()['weight'][0][0]=torch.tensor([[0.0,0.0,0.0],[0,0.5,0],[0.0,0.0,0.0]])\n",
    "conv4.state_dict()['weight'][0][1]=torch.tensor([[0.0,0.0,0.0],[0,0.5,0],[0.0,0.0,0.0]])\n",
    "\n",
    "\n",
    "conv4.state_dict()['weight'][1][0]=torch.tensor([[0.0,0.0,0.0],[0,1,0],[0.0,0.0,0.0]])\n",
    "conv4.state_dict()['weight'][1][1]=torch.tensor([[0.0,0.0,0.0],[0,-1,0],[0.0,0.0,0.0]])\n",
    "\n",
    "conv4.state_dict()['weight'][2][0]=torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0.0,-1.0]])\n",
    "conv4.state_dict()['weight'][2][1]=torch.tensor([[1.0,2.0,1.0],[0.0,0.0,0.0],[-1.0,-2.0,-1.0]])\n",
    "\n",
    "# Another example\n",
    "imageA=torch.zeros(1,1,5,5)\n",
    "imageB=torch.zeros(1,1,5,5)\n",
    "imageA[0,0,2,:]=-2\n",
    "imageB[0,0,2,:]=1\n",
    "\n",
    "conv5 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "conv6 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "\n",
    "Gx1=torch.tensor([[0.0,0.0,0.0],[0,1.0,0],[0.0,0.0,0.0]])\n",
    "conv5.state_dict()['weight'][0][0]=1*Gx1\n",
    "conv6.state_dict()['weight'][0][0]=-2*Gx1\n",
    "conv5.state_dict()['bias'][:]=torch.tensor([0.0])\n",
    "conv6.state_dict()['bias'][:]=torch.tensor([0.0])\n",
    "\n",
    "z=conv5(imageA) + conv6(imageB)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,out_1=2,out_2=1):\n",
    "        \n",
    "        super(CNN,self).__init__()\n",
    "        #first Convolutional layers \n",
    "        self.cnn1=nn.Conv2d(in_channels=1,out_channels=out_1,kernel_size=2,padding=0)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2 ,stride=1)\n",
    "\n",
    "        #second Convolutional layers\n",
    "        self.cnn2=nn.Conv2d(in_channels=out_1,out_channels=out_2,kernel_size=2,stride=1,padding=0)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2 ,stride=1)\n",
    "        #max pooling \n",
    "\n",
    "        #fully connected layer \n",
    "        self.fc1=nn.Linear(out_2*7*7,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #first Convolutional layers\n",
    "        x=self.cnn1(x)\n",
    "        #activation function \n",
    "        x=torch.relu(x)\n",
    "        #max pooling \n",
    "        x=self.maxpool1(x)\n",
    "        #first Convolutional layers\n",
    "        x=self.cnn2(x)\n",
    "        #activation function\n",
    "        x=torch.relu(x)\n",
    "        #max pooling\n",
    "        x=self.maxpool2(x)\n",
    "        #flatten output \n",
    "        x=x.view(x.size(0),-1)\n",
    "        #fully connected layer\n",
    "        x=self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def activations(self,x):\n",
    "        #outputs activation this is not necessary just for fun \n",
    "        z1=self.cnn1(x)\n",
    "        a1=torch.relu(z1)\n",
    "        out=self.maxpool1(a1)\n",
    "        \n",
    "        z2=self.cnn2(out)\n",
    "        a2=torch.relu(z2)\n",
    "        out=self.maxpool2(a2)\n",
    "        out=out.view(out.size(0),-1)\n",
    "        return z1,a1,z2,a2,out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN but with Batch Normalization\n",
    "class CNN_batch(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, out_1=16, out_2=32,number_of_classes=10):\n",
    "        super(CNN_batch, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(out_1)\n",
    "\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2_bn = nn.BatchNorm2d(out_2)\n",
    "\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, number_of_classes)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(10)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x=self.conv1_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x=self.conv2_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x=self.bn_fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Project - Convolutional Neural Network for Anime Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas==2.2.2\n",
    "%pip install numpy==1.26.4\n",
    "%pip install matplotlib==3.8.0\n",
    "%pip install scikit-learn==1.5.0\n",
    "%pip install torch==2.3.1\n",
    "%pip install torchvision==0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "def load_images_from_zip(zip_file):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        images = {'anastasia': [], 'takao': []}\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.startswith('anastasia') and file_name.endswith('.jpg'):\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    img = Image.open(file).convert('RGB')\n",
    "                    images['anastasia'].append(np.array(img))\n",
    "            elif file_name.startswith('takao') and file_name.endswith('.jpg'):\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    img = Image.open(file).convert('RGB')\n",
    "                    images['takao'].append(np.array(img))\n",
    "    return images\n",
    "\n",
    "zip_file_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/xZQHOyN8ONT92kH-ASb4Pw/data.zip'\n",
    "\n",
    "# Download the ZIP file\n",
    "response = requests.get(zip_file_url)\n",
    "zip_file_bytes = io.BytesIO(response.content)\n",
    "\n",
    "# Load images from zip file\n",
    "images = load_images_from_zip(zip_file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of images of Anastasia:\", len(images['anastasia']))\n",
    "print(\"Number of images of Takao:\", len(images['takao']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, title):\n",
    "    fig, axes = plt.subplots(5, 10, figsize=(10, 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot images from 'anastasia'\n",
    "plot_images(images['anastasia'], 'Anastasia Images')\n",
    "\n",
    "# Plot images from 'takao'\n",
    "plot_images(images['takao'], 'Takao Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeDataset(Dataset):\n",
    "    def __init__(self, images, transform=None, classes=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        \n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            for img in images[class_name]:\n",
    "                self.images.append(img)\n",
    "                self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = AnimeDataset(images, transform=transform, classes=['anastasia', 'takao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Generate a list of indices for the entire dataset\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "# Split the indices into training and validation sets\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Create samplers for training and validation sets\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Create DataLoader objects for training and validation sets\n",
    "train_loader = DataLoader(dataset, batch_size=8, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=20, sampler=val_sampler)\n",
    "\n",
    "# Print the sizes of the training and validation sets\n",
    "print(\"Train size:\", len(train_indices))\n",
    "print(\"Validation size:\", len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AnimeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AnimeCNN, self).__init__()\n",
    "        # Add padding=1 to maintain the border\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = AnimeCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, 64, 64)\n",
    "\n",
    "def print_size(module, input, output):\n",
    "    print(f\"{module.__class__.__name__} output size: {output.size()}\")\n",
    "\n",
    "# Register hooks\n",
    "hooks = []\n",
    "for layer in model.children():\n",
    "    hook = layer.register_forward_hook(print_size)\n",
    "    hooks.append(hook)\n",
    "\n",
    "# Inspect output sizes\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "print(\"Final output size:\", output.size())\n",
    "\n",
    "# Remove hooks\n",
    "for hook in hooks:\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss', linestyle='--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function to display an image\n",
    "def imshow(img, ax):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))  # Transpose dimensions to match matplotlib's expected format\n",
    "    ax.axis('off')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "data_iter = iter(val_loader)\n",
    "images, labels = next(data_iter)\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Define the grid size\n",
    "num_images = len(images)\n",
    "num_cols = 10\n",
    "num_rows = 2\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols * 2, figsize=(20, num_rows))\n",
    "\n",
    "for idx in range(num_images):\n",
    "    row = idx // num_cols\n",
    "    col = (idx % num_cols) * 2\n",
    "    \n",
    "    # Plot the image\n",
    "    imshow(images[idx].cpu(), axs[row, col])\n",
    "    \n",
    "    # Display actual and predicted labels\n",
    "    axs[row, col + 1].text(0.5, 0.5, f\"Actual: {labels[idx].item()}\\nPredicted: {predicted[idx].item()}\",\n",
    "                           horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
    "    axs[row, col + 1].axis('off')\n",
    "\n",
    "# Turn off any remaining empty subplots\n",
    "for idx in range(num_images, num_rows * num_cols):\n",
    "    row = idx // num_cols\n",
    "    col = (idx % num_cols) * 2\n",
    "    axs[row, col].axis('off')\n",
    "    axs[row, col + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Compute overall accuracy\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(f'correct: {correct}, total: {total}')\n",
    "\n",
    "print(f'Validation Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
