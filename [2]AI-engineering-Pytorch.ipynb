{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Engineering with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(1)\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.nn import Linear\n",
    "from torch import nn\n",
    "from mpl_toolkits import mplot3d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Tensors in 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vectors, please keep the parameters in the same length\n",
    "# @param: Vectors = [{\"vector\": vector variable, \"name\": name of vector, \"color\": color of the vector on diagram}]\n",
    "    \n",
    "def plotVec(vectors):\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    # For loop to draw the vectors\n",
    "    for vec in vectors:\n",
    "        ax.arrow(0, 0, *vec[\"vector\"], head_width = 0.05,color = vec[\"color\"], head_length = 0.1)\n",
    "        plt.text(*(vec[\"vector\"] + 0.1), vec[\"name\"])\n",
    "    \n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Basic Tensor Creation\n",
    "tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"Original Tensor:\\n\", tensor)\n",
    "\n",
    "# Get Tensor Shape\n",
    "print(\"Shape:\", tensor.shape)\n",
    "\n",
    "# Get Number of Dimensions\n",
    "print(\"Number of Dimensions:\", tensor.ndim)\n",
    "\n",
    "# Reshape Tensor using .view\n",
    "reshaped_tensor = tensor.view(4)  # Flatten to a 1D tensor\n",
    "print(\"Reshaped Tensor (1D):\", reshaped_tensor)\n",
    "\n",
    "reshaped_tensor = tensor.view(2, 2)  # Reshape back to 2x2\n",
    "print(\"Reshaped Tensor (2D):\\n\", reshaped_tensor)\n",
    "\n",
    "# Converting between pandas Series, numpy array, and torch tensor\n",
    "\n",
    "# From numpy to torch tensor\n",
    "np_array = np.array([5, 6, 7, 8])\n",
    "torch_from_np = torch.from_numpy(np_array)\n",
    "print(\"Torch Tensor from numpy:\\n\", torch_from_np)\n",
    "\n",
    "# From torch tensor to numpy array\n",
    "np_from_torch = torch_from_np.numpy()\n",
    "print(\"Numpy Array from torch:\\n\", np_from_torch)\n",
    "\n",
    "# From pandas Series to torch tensor\n",
    "pd_series = pd.Series([9, 10, 11, 12])\n",
    "torch_from_pd = torch.tensor(pd_series.values)\n",
    "print(\"Torch Tensor from pandas Series:\\n\", torch_from_pd)\n",
    "\n",
    "# From torch tensor to pandas Series\n",
    "pd_from_torch = pd.Series(torch_from_pd.numpy())\n",
    "print(\"Pandas Series from torch Tensor:\\n\", pd_from_torch)\n",
    "\n",
    "# Additional tensor operations\n",
    "print(\"Sum of Tensor Elements:\", tensor.sum())\n",
    "print(\"Mean of Tensor Elements:\", tensor.mean())\n",
    "print(\"Maximum Value in Tensor:\", tensor.max())\n",
    "\n",
    "# Moving tensor to GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    tensor_gpu = tensor.to('cuda')\n",
    "    print(\"Tensor moved to GPU:\\n\", tensor_gpu)\n",
    "else:\n",
    "    print(\"CUDA not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create two vectors (1D tensors)\n",
    "vector_a = torch.tensor([3.0, 4.0])\n",
    "vector_b = torch.tensor([1.0, 2.0])\n",
    "\n",
    "# Vector addition\n",
    "vector_sum = vector_a + vector_b\n",
    "print(\"Vector A:\", vector_a)\n",
    "print(\"Vector B:\", vector_b)\n",
    "print(\"Vector Sum (A + B):\", vector_sum)\n",
    "\n",
    "# Vector subtraction\n",
    "vector_diff = vector_a - vector_b\n",
    "print(\"Vector Difference (A - B):\", vector_diff)\n",
    "\n",
    "# Scalar multiplication\n",
    "scalar = 2.0\n",
    "scaled_vector = scalar * vector_a\n",
    "print(\"Scalar Multiplication (2 * A):\", scaled_vector)\n",
    "\n",
    "# Dot product\n",
    "dot_product = torch.dot(vector_a, vector_b)\n",
    "print(\"Dot Product of A and B:\", dot_product)\n",
    "\n",
    "# Cross product (requires 3D vectors)\n",
    "vector_a_3d = torch.tensor([1.0, 2.0, 3.0])\n",
    "vector_b_3d = torch.tensor([4.0, 5.0, 6.0])\n",
    "cross_product = torch.cross(vector_a_3d, vector_b_3d)\n",
    "print(\"Cross Product of A and B (3D):\", cross_product)\n",
    "\n",
    "# Element-wise multiplication\n",
    "elementwise_product = vector_a * vector_b\n",
    "print(\"Element-wise Multiplication (A * B):\", elementwise_product)\n",
    "\n",
    "# Norm (magnitude) of a vector\n",
    "vector_a_norm = torch.norm(vector_a)\n",
    "print(\"Norm (Magnitude) of Vector A:\", vector_a_norm)\n",
    "\n",
    "# Angle between vectors (cosine similarity)\n",
    "cos_theta = torch.dot(vector_a, vector_b) / (torch.norm(vector_a) * torch.norm(vector_b))\n",
    "print(\"Cosine Similarity (cos theta):\", cos_theta)\n",
    "\n",
    "# Plotting vector addition\n",
    "\n",
    "# Function to plot vectors\n",
    "def plot_vectors(vectors, colors, labels):\n",
    "    plt.figure()\n",
    "    for i, v in enumerate(vectors):\n",
    "        plt.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1, color=colors[i], label=labels[i])\n",
    "    plt.xlim(-1, 10)\n",
    "    plt.ylim(-1, 10)\n",
    "    plt.axhline(y=0, color='k')\n",
    "    plt.axvline(x=0, color='k')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot vector A, vector B, and their sum\n",
    "plot_vectors([vector_a, vector_b, vector_sum], colors=['r', 'b', 'g'], labels=['Vector A', 'Vector B', 'A + B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Dimensional Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create 2D tensors (matrices)\n",
    "matrix_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "matrix_b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print(\"Matrix A:\\n\", matrix_a)\n",
    "print(\"Matrix B:\\n\", matrix_b)\n",
    "\n",
    "# Matrix Addition (must be same shape)\n",
    "matrix_sum = matrix_a + matrix_b\n",
    "print(\"Matrix Sum (A + B):\\n\", matrix_sum)\n",
    "\n",
    "# Matrix Multiplication (Element-wise, requires same shape)\n",
    "elementwise_product = matrix_a * matrix_b\n",
    "print(\"Element-wise Multiplication (A * B):\\n\", elementwise_product)\n",
    "\n",
    "# Matrix Multiplication (Dot Product)\n",
    "# This requires the inner dimensions to match: (m x n) * (n x p) -> (m x p)\n",
    "matrix_c = torch.tensor([[1, 2], [3, 4], [5, 6]])  # Shape: (3x2)\n",
    "matrix_d = torch.tensor([[7, 8, 9], [10, 11, 12]])  # Shape: (2x3)\n",
    "dot_product = torch.matmul(matrix_c, matrix_d)  # Result: (3x3)\n",
    "print(\"Dot Product of C and D:\\n\", dot_product)\n",
    "\n",
    "# Matrix Transpose\n",
    "transpose_a = matrix_a.T  # or matrix_a.transpose(0, 1)\n",
    "print(\"Transpose of Matrix A:\\n\", transpose_a)\n",
    "\n",
    "# Matrix Broadcasting (handling unequal shapes)\n",
    "# If the shapes allow, broadcasting will expand the smaller matrix across the larger one.\n",
    "# Example: (2x1) with (2x3) - broadcast 1 column to 3 columns\n",
    "matrix_e = torch.tensor([[1], [2]])  # Shape: (2x1)\n",
    "broadcasted_sum = matrix_a + matrix_e\n",
    "print(\"Broadcasted Sum (A + E):\\n\", broadcasted_sum)\n",
    "\n",
    "# Matrix Inversion (only for square matrices)\n",
    "square_matrix = torch.tensor([[4.0, 7.0], [2.0, 6.0]])\n",
    "inverse_matrix = torch.inverse(square_matrix)\n",
    "print(\"Inverse of Square Matrix:\\n\", inverse_matrix)\n",
    "\n",
    "# Determinant of a square matrix\n",
    "determinant = torch.det(square_matrix)\n",
    "print(\"Determinant of Square Matrix:\", determinant)\n",
    "\n",
    "# Matrix Rank\n",
    "rank_a = torch.matrix_rank(matrix_a)\n",
    "print(\"Rank of Matrix A:\", rank_a)\n",
    "\n",
    "# Singular Value Decomposition (SVD)\n",
    "U, S, V = torch.svd(matrix_a.float())\n",
    "print(\"U Matrix:\\n\", U)\n",
    "print(\"Singular Values:\\n\", S)\n",
    "print(\"V Matrix:\\n\", V)\n",
    "\n",
    "# Concatenating matrices (if dimensions allow)\n",
    "# Concatenate along rows (dimension 0) or columns (dimension 1)\n",
    "concat_rows = torch.cat((matrix_a, matrix_b), dim=0)  # Stack matrices vertically\n",
    "print(\"Concatenation along rows:\\n\", concat_rows)\n",
    "concat_columns = torch.cat((matrix_a, matrix_b), dim=1)  # Stack matrices horizontally\n",
    "print(\"Concatenation along columns:\\n\", concat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom plotting function\n",
    "def plot_function_and_derivative(x_vals, func_vals, derivative_vals, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x_vals, func_vals, label=\"Function\", color=\"blue\")\n",
    "    plt.plot(x_vals, derivative_vals, label=\"Derivative\", color=\"red\", linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Define a function and calculate its derivative\n",
    "def compute_derivative():\n",
    "    # Create tensor with `requires_grad=True` to enable automatic differentiation\n",
    "    x = torch.linspace(-5, 5, 100, requires_grad=True)\n",
    "    y = x**2 + 3 * x + 5  # Define a sample function y = x^2 + 3x + 5\n",
    "\n",
    "    # Calculate derivative (dy/dx)\n",
    "    y.backward(torch.ones_like(x))  # Backpropagate to get the gradient\n",
    "    dy_dx = x.grad  # Retrieve the gradient of y with respect to x\n",
    "\n",
    "    # Convert tensors to numpy for plotting\n",
    "    x_vals = x.detach().numpy()\n",
    "    y_vals = y.detach().numpy()\n",
    "    dy_dx_vals = dy_dx.detach().numpy()\n",
    "\n",
    "    # Plot the function and its derivative\n",
    "    plot_function_and_derivative(x_vals, y_vals, dy_dx_vals, \"Function and its Derivative\")\n",
    "\n",
    "# Run the derivative calculation and plotting function\n",
    "compute_derivative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Dataset Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a custom dataset class, toy_set, which initializes a dataset with default tensor values for x and y, and includes support for applying a transformation function to each sample in the dataset. A sample at a given index can be retrieved using __getitem__, and the dataset length is defined by __len__. It then defines two transformation classes, add_mult and mult, which modify the x and y values by adding or multiplying them as specified. These transformations are then combined using transforms.Compose, and applied to a new instance of the toy_set dataset through the transform parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for dataset\n",
    "class toy_set(Dataset):\n",
    "    \n",
    "    # Constructor with defult values \n",
    "    def __init__(self, length = 100, transform = None):\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "     \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "# Create Dataset Object. Find out the value on index 1. Find out the length of Dataset Object.\n",
    "\n",
    "our_dataset = toy_set()\n",
    "print(\"Our toy_set object: \", our_dataset)\n",
    "print(\"Value on index 0 of our toy_set object: \", our_dataset[0])\n",
    "print(\"Our toy_set length: \", len(our_dataset))\n",
    "\n",
    "# Create tranform class add_mult\n",
    "class add_mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, addx = 1, muly = 2):\n",
    "        self.addx = addx\n",
    "        self.muly = muly\n",
    "    \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x + self.addx\n",
    "        y = y * self.muly\n",
    "        sample = x, y\n",
    "        return sample\n",
    "\n",
    "# Create tranform class mult\n",
    "class mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, mult = 100):\n",
    "        self.mult = mult\n",
    "        \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample\n",
    "    \n",
    "# Combine the add_mult() and mult()\n",
    "data_transform = transforms.Compose([add_mult(), mult()])\n",
    "print(\"The combination of transforms (Compose): \", data_transform)\n",
    "\n",
    "# Create a new toy_set object with compose object as transform\n",
    "compose_data_set = toy_set(transform = data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Datasets and Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Objective</h4><ul><li> How to build a image dataset object.</li><li> How to perform pre-build transforms from Torchvision Transforms to the dataset. .</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Create your own dataset object\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor to initialize the dataset object\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        \n",
    "        # Path to the directory containing images\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # Store the transform function for applying to images (optional)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load the CSV file that contains image paths and labels\n",
    "        data_dircsv_file = os.path.join(self.data_dir, csv_file)\n",
    "        self.data_name = pd.read_csv(data_dircsv_file)\n",
    "        \n",
    "        # Calculate the number of images in the dataset\n",
    "        self.len = self.data_name.shape[0] \n",
    "    \n",
    "    # Method to return the total number of images\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Method to get a specific image and its label by index\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Construct the full path to the image file\n",
    "        img_name = os.path.join(self.data_dir, self.data_name.iloc[idx, 1])\n",
    "        \n",
    "        # Open the image file using PIL\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # Get the class label for the image\n",
    "        y = self.data_name.iloc[idx, 0]\n",
    "        \n",
    "        # If a transform is specified, apply it to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define common transformations for image preprocessing\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),           # Resize image to 128x128 pixels\n",
    "    transforms.RandomHorizontalFlip(),       # Randomly flip image horizontally\n",
    "    transforms.ColorJitter(brightness=0.5),  # Adjust brightness randomly\n",
    "    transforms.ToTensor(),                   # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# Apply the transformations to the Dataset class\n",
    "dataset_with_transforms = Dataset(csv_file='images.csv', data_dir='data/images', transform=transform_pipeline)\n",
    "\n",
    "# Now dataset_with_transforms has transformations applied to every image retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading and displaying an image from the dataset with transforms applied\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image and its label\n",
    "image, label = dataset_with_transforms[0]\n",
    "\n",
    "# Convert tensor back to an image for displaying\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # Unnormalize if normalized earlier\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))  # Reorder dimensions for display\n",
    "    plt.show()\n",
    "\n",
    "# Display the image with label\n",
    "imshow(image)\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Combine vertical flip, horizontal flip and convert to tensor as a compose. Apply the compose on image. Then plot the image\n",
    "my_transform = transforms.Compose([transforms.RandomHorizontalFlip(p = 1), transforms.RandomVerticalFlip(p = 1), transforms.ToTensor()])\n",
    "dataset = dsets.MNIST(root = './data', download = True, transform = my_transform)\n",
    "show_data(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression 1D: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define w = 2 and b = -1 for y = wx + b\n",
    "w = torch.tensor(2.0, requires_grad = True)\n",
    "b = torch.tensor(-1.0, requires_grad = True)\n",
    "\n",
    "# Create Linear Regression Model, and print out the parameters\n",
    "lr = Linear(in_features=1, out_features=1, bias=True)\n",
    "print(\"Parameters w and b: \", list(lr.parameters()))\n",
    "\n",
    "# Print information about the model\n",
    "print(\"Python dictionary: \",lr.state_dict())\n",
    "print(\"keys: \",lr.state_dict().keys())\n",
    "print(\"values: \",lr.state_dict().values())\n",
    "print(\"weight:\",lr.weight)\n",
    "print(\"bias:\",lr.bias)\n",
    "\n",
    "# Create the prediction using linear model\n",
    "x = torch.tensor([[1.0], [2.0]])\n",
    "yhat = lr(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize Linear Regression Class\n",
    "\n",
    "class LR(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        # Inherit from parent\n",
    "        super(LR, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    # Prediction function\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "# Practice: Use the LR class to create a model and make a prediction of the following tensor.\n",
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "lr1 = LR(1, 1)\n",
    "yhat = lr1(x)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression 1D: Training One Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Learning Rate and an empty list to record the loss for each iteration\n",
    "lr = 0.1\n",
    "LOSS = []\n",
    "\n",
    "w = torch.tensor(-10.0, requires_grad = True)\n",
    "\n",
    "gradient_plot = plot_diagram(X, Y, w, stop = 5)\n",
    "\n",
    "# Define a function for train the model\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range (iter):\n",
    "        \n",
    "        # make the prediction as we learned in the last lab\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # calculate the iteration\n",
    "        loss = criterion(Yhat,Y)\n",
    "        \n",
    "        # plot the diagram for us to have a better idea\n",
    "        gradient_plot(Yhat, w, loss.item(), epoch)\n",
    "        \n",
    "        # store the loss into list\n",
    "        LOSS.append(loss.item())\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # updata parameters\n",
    "        w.data = w.data - lr * w.grad.data\n",
    "        \n",
    "        # zero the gradients before running the backward pass\n",
    "        w.grad.data.zero_()\n",
    "\n",
    "# Give 4 iterations for training the model here.\n",
    "train_model(4)\n",
    "\n",
    "# Plot the loss for each iteration\n",
    "plt.plot(LOSS)\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Epoch/Iterations\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression 1D: Training Two Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data for training\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "x_train = torch.linspace(0, 10, 100).reshape(-1, 1)  # 100 points in 1D\n",
    "y_train = 2 * x_train + 1 + torch.randn(x_train.size()) * 2  # y = 2x + 1 + noise\n",
    "\n",
    "# Define the Linear Regression Model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # 1 input, 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LinearRegressionModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Plot the results\n",
    "model.eval()\n",
    "predicted = model(x_train).detach()\n",
    "plt.scatter(x_train.numpy(), y_train.numpy(), label='Original Data')\n",
    "plt.plot(x_train.numpy(), predicted.numpy(), 'r', label='Fitted Line')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD) with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for training the model\n",
    "\n",
    "LOSS_SGD = []\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "\n",
    "def train_model_SGD(iter):\n",
    "    \n",
    "    # Loop\n",
    "    for epoch in range(iter):\n",
    "        \n",
    "        # SGD is an approximation of out true total loss/cost, in this line of code we calculate our true loss/cost and store it\n",
    "        Yhat = forward(X)\n",
    "\n",
    "        # store the loss \n",
    "        LOSS_SGD.append(criterion(Yhat, Y).tolist())\n",
    "        \n",
    "        for x, y in zip(X, Y):\n",
    "            \n",
    "            # make a pridiction\n",
    "            yhat = forward(x)\n",
    "        \n",
    "            # calculate the loss \n",
    "            loss = criterion(yhat, y)\n",
    "\n",
    "            # Section for plotting\n",
    "            get_surface.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "        \n",
    "            # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "            loss.backward()\n",
    "        \n",
    "            # update parameters slope and bias\n",
    "            w.data = w.data - lr * w.grad.data\n",
    "            b.data = b.data - lr * b.grad.data\n",
    "\n",
    "            # zero the gradients before running the backward pass\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()\n",
    "            \n",
    "        #plot surface and data space after each epoch    \n",
    "        get_surface.plot_ps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can use built in loss function like MSE\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Create optimizer\n",
    "model = linear_regression(1,1)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression: Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Learning Rate list, the error lists and the MODELS list\n",
    "learning_rates=[0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "train_error=torch.zeros(len(learning_rates))\n",
    "validation_error=torch.zeros(len(learning_rates))\n",
    "\n",
    "MODELS=[]\n",
    "\n",
    "# Define the train model function and train the model\n",
    "def train_model_with_lr (iter, lr_list):\n",
    "    \n",
    "    # iterate through different learning rates \n",
    "    for i, lr in enumerate(lr_list):\n",
    "        model = linear_regression(1, 1)\n",
    "        optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "        for epoch in range(iter):\n",
    "            for x, y in trainloader:\n",
    "                yhat = model(x)\n",
    "                loss = criterion(yhat, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        # train data\n",
    "        Yhat = model(train_data.x)\n",
    "        train_loss = criterion(Yhat, train_data.y)\n",
    "        train_error[i] = train_loss.item()\n",
    "    \n",
    "        # validation data\n",
    "        Yhat = model(val_data.x)\n",
    "        val_loss = criterion(Yhat, val_data.y)\n",
    "        validation_error[i] = val_loss.item()\n",
    "        MODELS.append(model)\n",
    "\n",
    "train_model_with_lr(10, learning_rates)\n",
    "\n",
    "# Plot the training loss and validation loss\n",
    "plt.semilogx(np.array(learning_rates), train_error.numpy(), label = 'training loss/total Loss')\n",
    "plt.semilogx(np.array(learning_rates), validation_error.numpy(), label = 'validation cost/total Loss')\n",
    "plt.ylabel('Cost\\ Total Loss')\n",
    "plt.xlabel('learning rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Sample data (features and target)\n",
    "X = torch.tensor([[11.0, 12.0, 13.0, 14.0], [11.0, 12.0, 13.0, 14.0]], requires_grad=True)\n",
    "y = torch.tensor([[30.0], [30.0]])\n",
    "\n",
    "# Define the linear regression model class\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    # Prediction function\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "input_size = X.shape[1]\n",
    "output_size = 1\n",
    "my_model = linear_regression(input_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    yhat = my_model(X)\n",
    "    loss = criterion(yhat, y)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss for every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test the model\n",
    "yhat = my_model(X)\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.arange(-100, 100, 0.1).view(-1, 1)\n",
    "print(\"The tensor: \", z)\n",
    "\n",
    "# Create sigmoid object\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "# Use sigmoid object to calculate the prediction \n",
    "yhat = sig(z)\n",
    "\n",
    "plt.plot(z.numpy(), yhat.numpy())\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('yhat')\n",
    "\n",
    "# Use sequential function to create model\n",
    "model = nn.Sequential(nn.Linear(1, 1), nn.Sigmoid())\n",
    "\n",
    "# Print the parameters\n",
    "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
    "print(\"\\nmodel.state_dict():\\n \", model.state_dict())\n",
    "\n",
    "# The prediction for x\n",
    "yhat = model(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic_regression custom class\n",
    "\n",
    "class logistic_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_inputs):\n",
    "        super(logistic_regression, self).__init__()\n",
    "        self.linear = nn.Linear(n_inputs, 1)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = torch.sigmoid(self.linear(x))\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
